# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
  - name: "python:3.11-slim"
    id: deploy-data-ingestion-pipeline-staging
    entrypoint: bash
    args:
      - -c
      - |
        cd data_ingestion && pip install uv==0.6.12 --user && cd data_ingestion_pipeline && \
        uv sync --locked && uv run python submit_pipeline.py
    env:
      - "PROJECT_ID=${_STAGING_PROJECT_ID}"
      - "PIPELINE_ROOT=${_PIPELINE_GCS_ROOT_STAGING}"
      - "REGION=${_REGION}"
      - "DATA_STORE_REGION=${_DATA_STORE_REGION}"
      - "DATA_STORE_ID=${_DATA_STORE_ID_STAGING}"
      - "STAGING_PROJECT_ID=${_STAGING_PROJECT_ID}"
      - "SERVICE_ACCOUNT=${_PIPELINE_SA_EMAIL_STAGING}"
      - "PIPELINE_NAME=${_PIPELINE_NAME}"
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
  # Build and Push with both commit SHA and latest tags
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/${_STAGING_PROJECT_ID}/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME:$COMMIT_SHA",
        "-t",
        "$_REGION-docker.pkg.dev/${_STAGING_PROJECT_ID}/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME:latest",
        "--build-arg",
        "COMMIT_SHA=$COMMIT_SHA",
        ".",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/${_STAGING_PROJECT_ID}/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME:$COMMIT_SHA",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/${_STAGING_PROJECT_ID}/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME:latest",
      ]

  # Deploy to Staging using commit SHA
  - name: "gcr.io/cloud-builders/gcloud"
    id: deploy-staging
    entrypoint: gcloud
    args:
      - "run"
      - "deploy"
      - "my-agentic-rag"
      - "--image"
      - "$_REGION-docker.pkg.dev/${_STAGING_PROJECT_ID}/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME:$COMMIT_SHA"
      - "--region"
      - "${_REGION}"
      - "--project"
      - "${_STAGING_PROJECT_ID}"

  # Fetch Staging Service URL
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-staging-url
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud run services describe my-agentic-rag \
        --region ${_REGION} --project ${_STAGING_PROJECT_ID} --format="value(status.url)") > staging_url.txt

  # Fetch ID Token
  - name: gcr.io/cloud-builders/gcloud
    id: fetch-id-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-identity-token -q) > id_token.txt

  # Load Testing
  - name: "python:3.11-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _ID_TOKEN=$(cat id_token.txt)
        export _STAGING_URL=$(cat staging_url.txt)
        pip install locust==2.31.1 --user
        locust -f tests/load_test/load_test.py \
        --headless \
        -H $$_STAGING_URL \
        -t 30s -u 10 -r 0.5 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'

  # Export Load Test Results to GCS
  - name: gcr.io/cloud-builders/gcloud
    id: export-results-to-gcs
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        gsutil -m cp -r tests/load_test/.results gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}
        echo "_________________________________________________________________________"
        echo "Load test results copied to gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "HTTP link: https://console.cloud.google.com/storage/browser/${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "_________________________________________________________________________"

  # Production deployment info
  - name: gcr.io/cloud-builders/gcloud
    id: echo-production-deployment-info
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo "_________________________________________________________________________"
        echo "âœ… Staging deployment successful!"
        echo "ðŸ“‹ To deploy to production, run:"
        echo "gcloud builds submit --config=.cloudbuild/deploy-to-prod.yaml --project=production-adk --region=us-central1 --substitutions=_SOURCE_BUCKET=${_BUCKET_NAME_LOAD_TEST_RESULTS}"
        echo ""
        echo "ðŸ”— Staging URL: $(cat staging_url.txt)"
        echo "ðŸ”— Load test results: https://console.cloud.google.com/storage/browser/${_BUCKET_NAME_LOAD_TEST_RESULTS}"
        echo "_________________________________________________________________________"

substitutions:
  _PROJECT_ID: staging-adk
  _STAGING_PROJECT_ID: staging-adk
  _REGION: us-central1
  _DATA_STORE_REGION: global
  _DATA_STORE_ID_STAGING: my-agentic-rag-datastore-staging
  _PIPELINE_GCS_ROOT_STAGING: gs://staging-adk-my-agentic-rag-pipeline-root/pipeline-runs
  _PIPELINE_SA_EMAIL_STAGING: my-agentic-rag-rag@staging-adk.iam.gserviceaccount.com
  _PIPELINE_NAME: data-ingestion-pipeline
  _ARTIFACT_REGISTRY_REPO_NAME: my-agentic-rag-docker-repo
  _CONTAINER_NAME: my-agentic-rag
  _BUCKET_NAME_LOAD_TEST_RESULTS: staging-adk-my-agentic-rag-load-test-results

logsBucket: gs://${_PROJECT_ID}-my-agentic-rag-logs-data/build-logs
options:
